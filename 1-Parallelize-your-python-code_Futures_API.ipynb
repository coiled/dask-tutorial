{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e414d3a-fd82-4af5-9a4e-d43a254d1d63",
   "metadata": {},
   "source": [
    "<img src=\"http://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg\"\n",
    "     align=\"right\"\n",
    "     width=\"30%\"\n",
    "     alt=\"Dask logo\\\">\n",
    "     \n",
    "# Parallelize your python code\n",
    "\n",
    "In this lesson you will learn how to paralellize custom python code using Dask. You will learn about the Futures and Delayed APIs, and how to use them to parallelize customs functions.\n",
    "\n",
    "The example we will be tackling consist of scrapping and cleaning some data from Stack Overflow website. But first let's do a quick recap on Futures and Delayed objects.\n",
    "\n",
    "## Futures: a low-level collection.\n",
    "\n",
    "Dask low-level collections are the best tools when you need to have fine control control to build custom parallel and distributed computations.\n",
    "\n",
    "**NOTE:** For an introductory lesson on futures revisit:\n",
    "- https://tutorial.dask.org/05_futures.html\n",
    "\n",
    "\n",
    "## Recap the Basics\n",
    "### Futures\n",
    "\n",
    "Submit arbitrary functions for computation in a parallelized, eager, and non-blocking way. \n",
    "\n",
    "The `futures` interface (derived from the built-in `concurrent.futures`) provide fine-grained real-time execution for custom situations. We can submit individual functions for evaluation with one set of inputs, or evaluated over a sequence of inputs with `submit()` and `map()`. The call returns immediately, giving one or more *futures*, whose status begins as \"pending\" and later becomes \"finished\". There is no blocking of the local Python session. With futures, as soon as the inputs are available and there is compute available, the computation starts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4fc278-3c14-4955-8b58-07524426b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9e13b-0ec7-4f18-a70e-eab2ea377ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=4)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8bf6e6-ff5a-49a9-b231-557155ceefa6",
   "metadata": {},
   "source": [
    "Let's make a toy functions, `inc`  that sleep for a while to simulate work. We'll then time running these functions normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c298e-296b-4070-88bc-a4caaf432f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "def inc(x):\n",
    "    sleep(1)\n",
    "    return x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111477d-d1c0-4735-a0ff-6cd596ae28a7",
   "metadata": {},
   "source": [
    "We can run these locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4581be1-68d1-4be9-aacf-62104e7bcb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f77ef-fb42-4ab2-acc9-a1785b88672e",
   "metadata": {},
   "source": [
    "**`client.submit()`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b692833-4618-406e-8914-f44e8270fb7d",
   "metadata": {},
   "source": [
    "Or we can submit them to run remotely with Dask. This immediately returns a future that points to the ongoing computation, and eventually to the stored result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94211742-96bf-4862-a41b-069447115afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = client.submit(inc, 1)  # returns immediately with pending future\n",
    "future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45ce68e-e9a9-4f0c-bfd5-68d3853a5e02",
   "metadata": {},
   "source": [
    "If you wait a second, and then check on the future again, youâ€™ll see that it has finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e01e2b-46c1-4822-8aa5-eb8bb782ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bf4e6a-8553-4383-b15a-c9f249bd71df",
   "metadata": {},
   "source": [
    "You can block on the computation and gather the result with the `.result()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9bf670-2d56-4a7a-bdb4-36791b91de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202e4b5d-b1c3-49f2-b5e7-5cc02602a4e4",
   "metadata": {},
   "source": [
    "**`client.map()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5576bf-3fdd-4fed-9419-a28ca323c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(inc, range(8))  # returns immediately with pending list of futures\n",
    "futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b34a6-fbd4-4ede-a9c0-9b90e71f4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_sum = client.submit(sum, futures)\n",
    "future_sum.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8248e9e5-08b5-496d-9c51-94119afed9fe",
   "metadata": {},
   "source": [
    "**`as_completed()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35499d7d-ec10-44db-8fbd-a7a061b3e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import as_completed\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb4ac56-bdee-4c6f-a8a8-6b66c12a974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_score(x):\n",
    "    return np.random.uniform(low=0.5, high=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2fc13-51be-43a0-b47a-b89db510ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_futures = client.map(random_score, range(20))\n",
    "\n",
    "best_score = 0\n",
    "for future in as_completed(score_futures):\n",
    "    score = future.result()\n",
    "    if score > best\n",
    "        best = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606792cf-422f-45bc-a570-bea637dfb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be9fac-d3a0-4150-9d45-4e2bb787abf8",
   "metadata": {},
   "source": [
    "**Useful links: futures**\n",
    "* [Futures documentation](https://docs.dask.org/en/latest/futures.html)\n",
    "* [Futures screencast](https://www.youtube.com/watch?v=07EiCpdhtDE)\n",
    "* [Futures examples](https://examples.dask.org/futures.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16467916-008c-4a21-bb1e-d374c530ee57",
   "metadata": {},
   "source": [
    "## Grown-up example: Scrapping and cleaning SO data\n",
    "\n",
    "In the re-cap as well as in plenty of introductory tutorials we use toy examples. In this section, we graduate to a grownup example. You will learn how to parallelize a scrapping and cleaning workflow.\n",
    "\n",
    "You'll be scraping multiple pages from https://stackoverflow.com/questions/, then you will be finding all the links for every post in each page and finally, getting some data from each post. You'll first see how the sequential code works, and then you'll use `futures` to do this in parallel\n",
    "\n",
    "Note about throttling:\n",
    "\n",
    "When scrapping directly from the pages and not using the API, it is not clear what are the throttling limitations, but from experience we run into them pretty quickly.\n",
    "\n",
    "The following examples, work as they are, if you change the number of pages you will likely hit a limit and be banned for few minutes. We will work around this towards the end, in the meantime avoid changing the number of pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a749874-4920-4b70-b709-832043039c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22c3321-d821-4c89-b90d-a1620312db0b",
   "metadata": {},
   "source": [
    "## Scrape, crawl, get data\n",
    "\n",
    "We wrote some functions that get a page and clean the data from all the posts in that page and returns it as a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1704e32d-926f-4eda-bde4-50a013e4b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_html_page(url):\n",
    "    req = requests.get(url)\n",
    "    html = bs(req.text, \"html.parser\")\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0494060-c49f-4e91-a53e-9c85c6e3611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_html_links(page_num, tag=\"dask\", query_filter = \"MostVotes\"):\n",
    "    base_url = \"https://stackoverflow.com/questions/tagged/\"\n",
    "    \n",
    "    page_url = f\"{base_url}{tag}?sort={query_filter}&page={page_num}\"\n",
    "\n",
    "    page_html = request_html_page(page_url)\n",
    "    \n",
    "    return page_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc0a27-ad44-43de-ab6e-71575527ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_links_per_page(html_page):\n",
    "    question_href = html_page.find_all(\"a\", class_=\"s-link\")[3:-1]\n",
    "    \n",
    "    question_link = [f\"https://stackoverflow.com{q['href']}\" for q in question_href]\n",
    "    \n",
    "    return question_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd88acf-eb3b-4d7d-8735-8449fc53b788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(post_link):\n",
    "    html_post = request_html_page(post_link)\n",
    "    post_info = {}\n",
    "    \n",
    "    \n",
    "    post_info[\"title\"] = html_post.title.text\n",
    "    post_info[\"question\"] = html_post.find(\"div\", class_=\"s-prose js-post-body\").text\n",
    "    \n",
    "    answ = html_post.find(\"div\", class_=\"answer\") #this will gets us the first/most voted answer\n",
    "    \n",
    "    if answ:\n",
    "        post_info[\"best_answer_votes\"] = int(answ[\"data-score\"])\n",
    "    \n",
    "        best_answer_author_obj = answ.find(\"span\", itemprop=\"name\")\n",
    "        \n",
    "        if best_answer_author_obj:\n",
    "            best_answer_author = best_answer_author_obj.text\n",
    "        else:\n",
    "            best_answer_author = \"comunity_post\"\n",
    "\n",
    "        post_info[\"best_answer_usrname\"] = best_answer_author\n",
    "    else:\n",
    "        post_info[\"best_answer_votes\"] = 0\n",
    "        post_info[\"best_answer_usrname\"] = \"no-answer\"\n",
    "\n",
    "    \n",
    "    return post_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea45c41-734c-4dc0-bc64-cd3b401eb9a6",
   "metadata": {},
   "source": [
    "## Serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2402f42a-e528-45dd-bce8-0b3bc64022f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_list =[]\n",
    "for page_num in range(1, 3): #more than 2 pages and get trhottling issues\n",
    "    page_html = get_page_html_links(page_num)\n",
    "    posts_links = get_post_links_per_page(page_html)\n",
    "    list_post_data = []\n",
    "    \n",
    "    for link in posts_links:\n",
    "        p_data = get_data(link)\n",
    "        list_post_data.append(p_data)\n",
    "\n",
    "    df = pd.DataFrame(list_post_data)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a0cf1-4b0c-48d9-a037-d43306ff510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc84dc-bd05-475a-be57-398e0fb391af",
   "metadata": {},
   "source": [
    "## Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f380cdb-2c52-48f5-b1b7-32549dcc704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import wait, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7870844e-5711-45fc-8b8c-81a397be48e5",
   "metadata": {},
   "source": [
    "### Get pages and links of posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41423031-c1ac-4070-b34d-c069a8cd1b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pages_futures = client.map(get_page_html_links, range(1,3))\n",
    "wait(pages_futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a37554-b0a5-4df0-bd73-2f2f5c9f5c30",
   "metadata": {},
   "source": [
    "**`wait()`**\n",
    "\n",
    "Notice that here we used `wait()`, you can wait on a future or collection of futures using the `wait` function, which blocks until all futures are finished or have erred. This is useful when you need the all the futures to be completed to proceed with your computations. \n",
    "\n",
    "**`as_completed()`**\n",
    "\n",
    "In other situations you might need to iterate over the futures as they complete, to do so you will use the `as_completed` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7792eff1-7013-4db8-bf0c-a5e13fbf8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "posts_links_futures = client.map(get_post_links_per_page, pages_futures)\n",
    "crawling = as_completed(posts_links_futures)\n",
    "\n",
    "dfs_data = []\n",
    "for future in crawling:\n",
    "    list_links = future.result() # list of links per page\n",
    "    df_data = []\n",
    "    for link in list_links:\n",
    "        fut_data = client.submit(get_data, link) \n",
    "        df_data.append(fut_data)\n",
    "\n",
    "    dfs_data.append(df_data)\n",
    "_ = wait(dfs_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c2fce7-3a4d-4d8c-9d39-1bb76bb581fc",
   "metadata": {},
   "source": [
    "## Avoid throttling using a cluster. \n",
    "\n",
    "In the example above, if we try to work with more pages, you will hit throttling issues. Sometimes you can avoid this problem by setting a sleep in the `requests` function, but in our case it is not clear what that time should be as there is not enough documentation. Besides, this will make things slower.\n",
    "\n",
    "However, we have a nice solution to be able to scrape more pages. When using a cluster each worker has its own public ip-address so it is like we are requesting from different machines. \n",
    "\n",
    "Let's create a coiled cluster and scrape a bigger number of pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cab38-f727-454d-b901-33f70b86a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shutdown LocalCluster\n",
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81208e-1075-412a-ac48-e2193c984acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91a1f5-b9e1-4553-b9c4-3da14127c59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = coiled.Cluster(n_workers=10, \n",
    "                        package_sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334ae4e-43a2-450e-a6fc-7f1b9c302f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client =  Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e1817-fe7a-4d3c-927e-44db2f5be74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pages_10_futures = client.map(get_page_html_links, range(1,11))\n",
    "wait(pages_10_futures)\n",
    "\n",
    "posts_links_futures = client.map(get_post_links_per_page, pages_10_futures)\n",
    "crawling = as_completed(posts_links_futures)\n",
    "\n",
    "dfs_data = []\n",
    "for future in crawling:\n",
    "    list_links = future.result() # list of links per page\n",
    "    df_data = []\n",
    "    for link in list_links:\n",
    "        fut_data = client.submit(get_data, link) \n",
    "        df_data.append(fut_data)\n",
    "\n",
    "    dfs_data.append(df_data)\n",
    "_ = wait(dfs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a64300-e971-4235-b9a9-b16c778c1069",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs_data) #10 pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fda0881-f0a1-47d0-b019-8f7c4270b5f7",
   "metadata": {},
   "source": [
    "At this point, we have the data to build each page dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67513dcf-0ee9-4981-a948-8f3697d0db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6a460c-b313-4c2b-9084-8d25ea490365",
   "metadata": {},
   "source": [
    "To get a dataframe per page, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13dedd5-18c7-41b4-b0a7-755502554b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_futures = client.map(pd.DataFrame, dfs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97d442-f647-4a86-82f9-78bf85efd327",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_futures[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a749893-30d1-4427-a293-ed91ef14ab5a",
   "metadata": {},
   "source": [
    "We can do multiple operations on these dataframes using `futures` but at this point since wer are working with dataframes we can use `dask.dataframes`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4429b8f4-79f5-4af4-a3cb-30d1730d82d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63bef3e-9532-4fbe-b58e-2699633074bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_so = dd.from_delayed(df_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b6c1d-84e8-4160-a0b3-c0a38469fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b05936-5863-4583-b0f0-44fe6fa44c00",
   "metadata": {},
   "source": [
    "### Dask dataframes API\n",
    "\n",
    "Now we are on dataframe world, we can do pandas-like operations, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f19f68-1dee-4e4a-a748-df96260843aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_so.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158c1bce-23af-4310-ba78-cadfede71968",
   "metadata": {},
   "source": [
    "We can check which of the user tht got a best answer, has the most \"best answers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c70813-5717-49c7-86ba-f705e1f32520",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_so.best_answer_usrname.value_counts().compute()[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc30dc2e-c409-4b1c-ab76-1345f3d279da",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can also check how many votes, this users got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8e18a-3004-4c5f-8e26-6a92fc65768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##sort? \n",
    "ddf_so.groupby(\"best_answer_usrname\")['best_answer_votes'].sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f28d2f-2b44-428c-afca-402b7988a6ea",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "\n",
    "Modify the following code, to get a different tag (e.g `tag=\"python\"`) and re-run the experiment\n",
    "\n",
    "```python\n",
    "pages_futures = client.map(get_page_html_links, range(1,3))\n",
    "wait(pages_futures)\n",
    "```\n",
    "\n",
    "Hint: You can use `client.map()` with `lambda` functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1027730-c892-469d-916e-1b4ea6897849",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Solution\n",
    "pages_py_futures = client.map(lambda p: get_page_html_links(p, tag=\"python\"), range(1, 5))\n",
    "wait(pages_py_futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a7a6ef-b94b-46f8-af23-1a7ef27725f4",
   "metadata": {},
   "source": [
    "### Useful links\n",
    "\n",
    "- https://tutorial.dask.org/05_futures.html\n",
    "\n",
    "**Useful links**\n",
    "\n",
    "* [Futures documentation](https://docs.dask.org/en/latest/futures.html)\n",
    "* [Futures screencast](https://www.youtube.com/watch?v=07EiCpdhtDE)\n",
    "* [Futures examples](https://examples.dask.org/futures.html)\n",
    "\n",
    "### Next lesson\n",
    "\n",
    "In the next lesson, you will get better at `dask.Dataframes`. We will re-cap the basics, but dive deeper into data formats (csv vs parquet),  learn about `pyarrow-strings`, shuffle operations, and other useful content that is not usually covered in the introductory material\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
