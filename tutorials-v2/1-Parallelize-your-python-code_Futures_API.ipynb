{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd982e68-605d-461d-a0f1-0166ebb1e55c",
   "metadata": {},
   "source": [
    "<img src=\"images/coiled-logo.svg\"\n",
    "     align=\"right\"\n",
    "     width=\"5%\"\n",
    "     alt=\"Coiled logo\\\">\n",
    "\n",
    "### Sign up for the next live session https://www.coiled.io/tutorials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c1daa-d1af-45b1-bcfc-4d56fd3b7593",
   "metadata": {},
   "source": [
    "<img src=\"http://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg\"\n",
    "     align=\"right\"\n",
    "     width=\"30%\"\n",
    "     alt=\"Dask logo\\\">\n",
    "     \n",
    "# Parallelize your Python code\n",
    "\n",
    "In this lesson you will learn how to parallelize custom Python code using Dask using the Futures API. We will take normal for-loopy Python code that looks like this:\n",
    "\n",
    "```python\n",
    "urls = [...]\n",
    "results = []\n",
    "for url in urls:\n",
    "    page = download(url)\n",
    "    result = process(page)\n",
    "    results.append(result)\n",
    "```\n",
    "\n",
    "or more dynamic Python code that looks like this:\n",
    "\n",
    "```python\n",
    "urls = [...]\n",
    "results = []\n",
    "while urls:\n",
    "    url = urls.pop()\n",
    "    page = download(url)\n",
    "    result = process(page)\n",
    "    results.append(result)\n",
    "    \n",
    "    new_urls = scrape(page)\n",
    "    urls.extend(new_urls)\n",
    "```\n",
    "\n",
    "and parallelize it using [Dask Futures](https://docs.dask.org/en/stable/futures.html). \n",
    "\n",
    "\n",
    "## Futures: a low-level collection.\n",
    "\n",
    "Dask low-level collections are the best tools when you need to have fine control to build custom parallel and distributed computations. \n",
    "\n",
    "The `futures` interface (derived from the built-in `concurrent.futures`) provides fine-grained real-time execution for custom situations. It allows you to submit arbitrary functions for computation in a parallelized, eager, and non-blocking way. \n",
    "\n",
    "### Why use Futures?\n",
    "\n",
    "The `futures` API offers a work submission style that can easily emulate the map/reduce paradigm. If that is familiar to you then futures might be the simplest entrypoint into Dask.\n",
    "\n",
    "The other big benefit of futures is that the intermediate results, represented by futures, can be passed to new tasks without having to pull data locally from the cluster. The **call returns immediately**, giving one or more *futures*, whose status begins as \"pending\" and later becomes \"finished\". There is no blocking of the local Python session. With futures, as soon as the inputs are available and there is compute available, the computation starts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abb22f5-3030-4357-8cfd-baa1ccbe3909",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "We will learn how to use futures, and then use them on a real-world example, first in a simple case, and then in a complex case:\n",
    "\n",
    "1.  How to use Futures \n",
    "2.  Use futures to download and parse webpages\n",
    "3.  Dynamic/changing workloads\n",
    "4.  Crawl and scrape a website\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a67dbd-765c-4459-9a60-5002f72d889e",
   "metadata": {},
   "source": [
    "### Parallel Code with low-level Futures\n",
    "\n",
    "This is an example of an embarrassingly parallel computation.  We want to run the same Python code on many pieces of data.  This is a very simple and also very common case that comes up all the time.\n",
    "\n",
    "First, we're going to see a very simple example, then we'll try to parallelize the code above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37bef54-58d1-4ac7-802b-518bcbb10cb3",
   "metadata": {},
   "source": [
    "### Set up a Dask cluster locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cae81cd-7b3b-42c1-98bf-d83eaaf9b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301907f-8c9d-4f49-9873-ea57a2595e15",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dask Futures introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0744577-3f0b-4dec-a427-f4af4ed907d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "def inc(x):\n",
    "    time.sleep(random.random())\n",
    "    return x + 1\n",
    "\n",
    "def double(x):\n",
    "    time.sleep(random.random())\n",
    "    return 2 * x\n",
    "\n",
    "def add(x, y):\n",
    "    time.sleep(random.random())\n",
    "    return 2 * x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d9a8b-5424-46ee-8cd1-ae516b1cb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y = inc(10)\n",
    "z = double(y)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936d4ac8-9939-4195-84c1-37e90b67bc58",
   "metadata": {},
   "source": [
    "Dask futures lets us run Python functions remotely on parallel hardware.  Rather than calling the function directly, like in the cell above, we can ask Dask to run that function, `inc` on the data `10` by passing each as arguments into the `client.submit` method.  The first argument is the function to call and the rest of the arguments are arguments to that function.\n",
    "\n",
    "Normal Execution\n",
    "\n",
    "```python\n",
    "result = function(*args, **kwargs)   # e.g inc(10)\n",
    "```\n",
    "\n",
    "Submit function for remote execution\n",
    "\n",
    "```python\n",
    "future = client.submit(function, *args, **kwargs)  # instantaneously fire off work\n",
    "...\n",
    "result = future.result()  # when we need, block until done and collect the result\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c397a32-a6fa-4e7b-aa69-cb2eb930e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y = client.submit(inc, 10)\n",
    "z = client.submit(double, y)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc6676-bb3b-4635-b2e2-7561f4cfeef9",
   "metadata": {},
   "source": [
    "You'll notice that that happened immediately.  That's because all we did was submit the `inc` function to run on Dask, and then return a `Future`, or a pointer to where the data will eventually be.\n",
    "\n",
    "We can gather the future by calling `future.result()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972bc35b-bd30-427e-bcab-2a424c157cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a4bd1e-a269-4b86-be47-ecbcce873c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22280cd9-1bb6-469f-9434-99c716e3d59c",
   "metadata": {},
   "source": [
    "### Submit many tasks in a loop\n",
    "\n",
    "We can submit lots of functions to run at once, and then gather them when we're done.  This allows us to easily parallelize simple for loops.\n",
    "\n",
    "*This section uses the following API*:\n",
    "\n",
    "-  [Client.submit and Future.result](https://docs.dask.org/en/stable/futures.html#submit-tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fcf290-6638-4877-b719-fabe9a654347",
   "metadata": {},
   "source": [
    "#### Sequential code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1b192-0ca7-4ead-b738-92e632f3eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "results = []\n",
    "\n",
    "for x in data:\n",
    "    y = inc(x)\n",
    "    z = double(y)\n",
    "    results.append(z)\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e16d8c-d49d-451c-b416-f0b1bea0d2fc",
   "metadata": {},
   "source": [
    "#### Parallel code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34cfb1-1d84-445c-8094-eac1a7e0f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "results = []\n",
    "\n",
    "for x in data:\n",
    "    y = client.submit(inc, x)\n",
    "    z = client.submit(double, y)\n",
    "    results.append(z)\n",
    "    \n",
    "results = client.gather(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7393bff-27b0-46f7-bba7-b6d4c8c56f62",
   "metadata": {},
   "source": [
    "### Lessons:\n",
    "\n",
    "1.  Submit a function to run elsewhere\n",
    "\n",
    "    ```python\n",
    "    y = f(x)\n",
    "    future = client.submit(f, x)\n",
    "    ```\n",
    "    \n",
    "    \n",
    "2.  Get results when you're done\n",
    "\n",
    "    ```python\n",
    "    y = future.result()\n",
    "    # or \n",
    "    results = client.gather(futures)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e364aee-cb00-4b67-8cba-444af569f80e",
   "metadata": {},
   "source": [
    "## Use futures to download and parse webpages\n",
    "\n",
    "### Sequential Code\n",
    "\n",
    "The code below downloads 50 question pages from a Stack Overflow tag, parses those pages, and collects the title and list of tags from each page.\n",
    "\n",
    "We then count up all the tags to see what are the most popular kinds of questions.  We divide this code into four sections:\n",
    "\n",
    "1.  Define useful functions\n",
    "2.  Get a list of pages to download and scrape\n",
    "3.  Download and scrape\n",
    "4.  Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abce7ac1-7e53-480e-869e-e97afc8f15f1",
   "metadata": {},
   "source": [
    "#### Define useful functions\n",
    "\n",
    "You don't need to study these.  Feel free to skip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf48fc6-b488-4266-95c0-83ac57c04173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def download(url: str, delay=0) -> str:\n",
    "    time.sleep(delay)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        \n",
    "def scrape_title(body: str) -> str:\n",
    "    html = BeautifulSoup(body, \"html.parser\")\n",
    "    return str(html.html.title)\n",
    "\n",
    "\n",
    "def scrape_links(body: str, base_url=\"\") -> list[str]:\n",
    "    html = BeautifulSoup(body, \"html.parser\")\n",
    "    \n",
    "    return [\n",
    "        str(base_url + link.attrs[\"href\"]).split(\"?\")[0]\n",
    "        for link in html.find_all(\"a\") \n",
    "        if re.match(\"/questions/\\d{5}\", link.attrs.get(\"href\", \"\"))\n",
    "    ]\n",
    "\n",
    "\n",
    "def scrape_tags(body: str) -> list[str]:\n",
    "    html = BeautifulSoup(body, \"html.parser\")\n",
    "    \n",
    "    return sorted({\n",
    "        str(list(link.children)[0])\n",
    "        for link in html.find_all(\"a\", class_=\"post-tag\")\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb36481-ad2f-4a3c-a3f5-7ef39b02bcb3",
   "metadata": {},
   "source": [
    "### Serial for-loopy code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eae6b5-22b6-40b8-a146-de174b2a1fdb",
   "metadata": {},
   "source": [
    "#### Get list of pages to download and scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04dc62-abcc-4e77-b127-c7ad6e31c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://stackoverflow.com/questions/tagged/dask\"\n",
    "body = download(url)\n",
    "urls = scrape_links(body, base_url=\"https://stackoverflow.com\")\n",
    "urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d107cc-e13c-498e-afaf-6af47d0ac1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a618f52-b89b-4988-930e-8f9a46f2beba",
   "metadata": {},
   "source": [
    "#### Download and scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac648177-8525-446c-b9fd-85698ef2a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_tags = []\n",
    "titles = []\n",
    "\n",
    "for url in urls:\n",
    "    page = download(url)\n",
    "    print(\".\", end=\"\")\n",
    "    tags = scrape_tags(page)\n",
    "    title = scrape_title(page)\n",
    "    \n",
    "    all_tags.append(tags)\n",
    "    titles.append(title)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c30b7-dd2b-4d84-b43c-0e31574bbc96",
   "metadata": {},
   "source": [
    "#### Analyze Results\n",
    "\n",
    "Aggregate tags to find related topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b06197-f8a2-4e2c-8a9d-f19c0dad1d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "tag_counter = collections.defaultdict(int)\n",
    "\n",
    "for tags in all_tags:\n",
    "    for tag in tags:\n",
    "        tag_counter[tag] += 1\n",
    "        \n",
    "sorted(tag_counter.items(), key=lambda kv: kv[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624ee94-5cbe-43be-b37f-f3d64375fb7c",
   "metadata": {},
   "source": [
    "### Exercise: Parallelize this code\n",
    "\n",
    "Take the code above, and use Dask futures to run it in parallel\n",
    "\n",
    "Which sections should we think about parallelizing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07a529-7a06-4fb8-987c-d9c0b3a346f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://stackoverflow.com/questions/tagged/dask\"\n",
    "body = download(url)\n",
    "urls = scrape_links(body, base_url=\"https://stackoverflow.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f891e-9cb6-46bb-9ad1-172e0e3fb236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: parallelize me\n",
    "\n",
    "%%time\n",
    "\n",
    "all_tags = []\n",
    "titles = []\n",
    "\n",
    "for url in urls:\n",
    "    page = download(url)\n",
    "    tags = scrape_tags(page)\n",
    "    title = scrape_title(page)\n",
    "    \n",
    "    all_tags.append(tags)\n",
    "    titles.append(title)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f7d1d0-0f3a-4ff4-9f7f-3e9b5b5b1bd6",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "\n",
    "Expand the three dots below if you want to see the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65abf2-b2a2-4c15-b991-d030b88d01ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_tags = []\n",
    "titles = []\n",
    "\n",
    "for url in urls:\n",
    "    page = client.submit(download, url)\n",
    "    tags = client.submit(scrape_tags, page)\n",
    "    title = client.submit(scrape_title, page)\n",
    "    \n",
    "    all_tags.append(tags)\n",
    "    titles.append(title)\n",
    "    \n",
    "all_tags = client.gather(all_tags)\n",
    "titles = client.gather(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9536ff6a-9247-414d-bcab-bb414cc8ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "tag_counter = collections.defaultdict(int)\n",
    "\n",
    "for tags in all_tags:\n",
    "    for tag in tags:\n",
    "        tag_counter[tag] += 1\n",
    "        \n",
    "sorted(tag_counter.items(), key=lambda kv: kv[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a0c0c5-4656-41e4-b701-d9b26b09921b",
   "metadata": {},
   "source": [
    "### Exercise:  Scale out\n",
    "\n",
    "There are different reasons to scale out for this problem:\n",
    "\n",
    "1.  Parallelize bandwidth\n",
    "2.  StackOverflow's rate-limits won't affect us as much if we spread out our requests from many different machines\n",
    "3.  ~CPU Processing speed~ (not really an issue here)\n",
    "\n",
    "Let's ask for some machines from Coiled, and switch our Dask client to use that cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164349e-185f-4040-85db-1bb58a181e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2656f3c-2ed4-4c46-b2c9-2559a42f663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled\n",
    "\n",
    "cluster = coiled.Cluster(\n",
    "    n_workers=20,\n",
    "    account=\"dask-tutorials\",\n",
    ")\n",
    "\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5152a8-fc00-4c44-8f59-23d320d5aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4ef8ef-05a1-49d9-b07c-01c8c3dcbbc2",
   "metadata": {},
   "source": [
    "**Rerun your computation and see.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b692762-e08f-4856-b07e-c24ef9685851",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9cb8c5-723b-423c-85d5-8bfa82454e3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_tags = []\n",
    "titles = []\n",
    "\n",
    "for url in urls:\n",
    "    page = client.submit(download, url)\n",
    "    tags = client.submit(scrape_tags, page)\n",
    "    title = client.submit(scrape_title, page)\n",
    "    \n",
    "    all_tags.append(tags)\n",
    "    titles.append(title)\n",
    "    \n",
    "all_tags = client.gather(all_tags)\n",
    "titles = client.gather(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a9bd0-f8f1-4111-a591-eb21fc1ce03e",
   "metadata": {},
   "source": [
    "## 3. Evolving computations\n",
    "\n",
    "Dask futures are flexible.  There are many ways to coordinate them including ...\n",
    "\n",
    "1.  Distributed locks and semaphores\n",
    "2.  Distributed queues\n",
    "3.  Launching tasks from tasks\n",
    "4.  Global variables\n",
    "5.  ... [and lots more](https://docs.dask.org/en/stable/futures.html)\n",
    "\n",
    "We're going to get a taste of this by learning about one Dask futures feature, [`as_completed`](https://docs.dask.org/en/stable/futures.html#distributed.as_completed), which lets us dynamically build up a computation as it completes.\n",
    "\n",
    "We will use this to build a parallel web crawler over Stack Overflow.  \n",
    "\n",
    "1.  First, we'll build this sequentially.\n",
    "2.  Second, we'll learn how `as_completed` works in a simple example\n",
    "3.  Third, we'll convert the sequential code into parallel code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935e9a45-b547-48ee-bbec-efa69793368a",
   "metadata": {},
   "source": [
    "### Sequential Code to Crawl Stack Overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd922ee-db5c-480b-98f4-40365df48dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from collections import deque\n",
    "\n",
    "urls = deque()\n",
    "urls.append(\"https://stackoverflow.com/questions/tagged/dask\")  # seed with a single page\n",
    "\n",
    "all_tags = []\n",
    "titles = []\n",
    "seen = set()\n",
    "i = 0\n",
    "\n",
    "while urls and i < 10: \n",
    "    url = urls.popleft()\n",
    "    \n",
    "    # Don't scrape the same page twice\n",
    "    if url in seen:  \n",
    "        continue\n",
    "    else:\n",
    "        seen.add(url)\n",
    "    \n",
    "    print(\".\", end=\"\")\n",
    "    i += 1\n",
    "    \n",
    "    # This is like before\n",
    "    page = download(url)\n",
    "    tags = scrape_tags(page)\n",
    "    title = scrape_title(page)\n",
    "    all_tags.append(tags)\n",
    "    titles.append(title)\n",
    "\n",
    "    # This is new!  \n",
    "    # We scrape links on this page, and add them to the list of URLs\n",
    "    new_urls = scrape_links(page, base_url=\"https://stackoverflow.com\")\n",
    "    urls.extend(new_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ee92de-c1c2-44e3-ab55-62bb18b5d507",
   "metadata": {},
   "source": [
    "## Exercise: Parallelize code to crawl Stack Overflow\n",
    "\n",
    "Expand the sequential code that we saw below. Parallelize it with futures and as_completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1cd8d9-525d-4a1d-bd2d-4fa518ba71c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from dask.distributed import as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec078790-36ef-4e54-91ce-b91c02b95b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "urls = deque()\n",
    "urls.append(\"https://stackoverflow.com/questions/tagged/dask\")  # seed with a single page\n",
    "\n",
    "all_tags = []\n",
    "titles = []\n",
    "url_futures = as_completed()\n",
    "seen = set()\n",
    "i = 0\n",
    "\n",
    "while urls or not url_futures.is_empty() and i < 1000:\n",
    "    \n",
    "    # TODO: If urls is empty, \n",
    "    #   get the next future from url_futures\n",
    "    #   collect those new url results to the local notebook\n",
    "    #   and add those new urls to urls\n",
    "\n",
    "    url = urls.popleft()\n",
    "\n",
    "    if url in seen:\n",
    "        continue\n",
    "    else:\n",
    "        seen.add(url)\n",
    "    \n",
    "    print(\".\", end=\"\")\n",
    "    i += 1\n",
    "\n",
    "    # This is like before\n",
    "    # TODO: Submit this work to happen in parallel\n",
    "    page = download(url, delay=0.25)\n",
    "    tags = scrape_tags(page)\n",
    "    title = scrape_title(page)\n",
    "    \n",
    "    all_tags.append(tags)\n",
    "    titles.append(title)\n",
    "\n",
    "    # We scrape links on this page, and add them to the list of URLs\n",
    "    # TODO: Submit this work to happen in parallel.  Add the future to url_futures\n",
    "    new_urls = scrape_question_links(page, base_url=\"https://stackoverflow.com\")\n",
    "    urls.extend(new_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50258b6-d4a5-47d2-8a0a-739bf68c850d",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92efc708-316c-408a-8806-ac65ec124ec2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "urls = deque()\n",
    "urls.append(\"https://stackoverflow.com/questions/tagged/dask\")  # seed with a single page\n",
    "\n",
    "all_tags = []\n",
    "titles = []\n",
    "url_futures = as_completed()\n",
    "seen = set()\n",
    "i = 0\n",
    "\n",
    "while urls or not url_futures.is_empty() and i < 1000:\n",
    "    \n",
    "    # TODO: If urls is empty, \n",
    "    #   get the next future from url_futures\n",
    "    #   collect those new url results to the local notebook\n",
    "    #   and add those new urls to urls\n",
    "    if not urls:\n",
    "        future = url_futures.next()\n",
    "        new_urls = future.result()\n",
    "        urls.extend(new_urls)\n",
    "        continue\n",
    "    \n",
    "    url = urls.popleft()\n",
    "    \n",
    "    if url in seen:\n",
    "        continue\n",
    "    else:\n",
    "        seen.add(url)\n",
    "    \n",
    "    print(\".\", end=\"\")\n",
    "    i += 1\n",
    "\n",
    "    # This is like before\n",
    "    # TODO: Submit this work to happen in parallel\n",
    "    page = client.submit(download, url, delay=0.25)\n",
    "    tags = client.submit(scrape_tags, page)\n",
    "    title = client.submit(scrape_title, page)\n",
    "\n",
    "    all_tags.append(tags)\n",
    "    titles.append(title)\n",
    "    \n",
    "    # We scrape links on this page, and add them to the list of URLs\n",
    "    # TODO: Submit this work to happen in parallel.  Add the future to url_futures\n",
    "    new_urls = client.submit(scrape_links, page, base_url=\"https://stackoverflow.com\")\n",
    "    url_futures.add(new_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcda5db-d6eb-4b3c-9140-e45254953029",
   "metadata": {},
   "source": [
    "### Analyze results\n",
    "\n",
    "At this point you likely have lists `titles` and `all_tags` that are lists of futures.  Let's gather them and analyze results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d12830-10d1-4fca-a6c7-4ca6ecc5ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = client.gather(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dcb1d1-826f-4957-8711-2c6b3058afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81c4b16-b2ba-4234-980f-e4af10c21779",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b1923a-a4f7-452b-9801-3e83fb473fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = client.gather(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd8656-90af-4381-beb5-58ad12cc7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "tag_counter = collections.defaultdict(int)\n",
    "\n",
    "for tags in all_tags:\n",
    "    for tag in tags:\n",
    "        tag_counter[tag] += 1\n",
    "        \n",
    "sorted(tag_counter.items(), key=lambda kv: kv[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39486ea8-930c-46fe-a0a9-f88b9e8ad940",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852e4ac-4a15-461a-9d59-5bb65115ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d6a9cd-2d15-4ef4-9d8b-4f6ada4d9904",
   "metadata": {},
   "source": [
    "### Useful links\n",
    "\n",
    "- https://tutorial.dask.org/05_futures.html\n",
    "- [Futures documentation](https://docs.dask.org/en/latest/futures.html)\n",
    "- [Futures screencast](https://www.youtube.com/watch?v=07EiCpdhtDE)\n",
    "- [Futures examples](https://examples.dask.org/futures.html)\n",
    "\n",
    "### More Dask Tutorials\n",
    "\n",
    "Coiled also runs regular Dask tutorials.  See [coiled.io/tutorials](https://www.coiled.io/tutorials) for more information. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
